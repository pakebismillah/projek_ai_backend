// backend/agent/agent.js
import { ChatOpenAI } from "@langchain/openai";
import { BufferMemory, ChatMessageHistory } from "langchain/memory";
import { ChatMessage } from "../models/Models.js";
import { RunnableSequence } from "@langchain/core/runnables";
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
} from "@langchain/core/prompts";

const llm = new ChatOpenAI({
  modelName: "gpt-4o-mini",
  temperature: 0.7,
  apiKey: process.env.OPENAI_API_KEY,
});

export async function askAgent(sessionId, userMessage) {
  console.log(
    "ğŸ§  askAgent called with sessionId:",
    sessionId,
    "and message:",
    userMessage
  );

  // 1ï¸âƒ£ Ambil history dari DB
  const historyMessages = await ChatMessage.findAll({
    where: { sessionId },
    order: [["createdAt", "ASC"]],
  });
  console.log("ğŸ“œ Loaded history messages:", historyMessages.length);

  // 2ï¸âƒ£ Konversi ke format LangChain
  const chatHistory = new ChatMessageHistory();
  for (const msg of historyMessages) {
    console.log(`   â†³ ${msg.role}: ${msg.content}`);
    if (msg.role === "user") chatHistory.addUserMessage(msg.content);
    else if (msg.role === "assistant") chatHistory.addAIMessage(msg.content);
  }

  // 3ï¸âƒ£ Setup memory
  const memory = new BufferMemory({
    chatHistory,
    returnMessages: true,
    memoryKey: "history",
    inputKey: "input",
    outputKey: "output",
  });
  console.log("ğŸ’¾ Memory initialized");

  // 4ï¸âƒ£ Template prompt
  const prompt = ChatPromptTemplate.fromMessages([
    new MessagesPlaceholder("history"),
    ["human", "{input}"],
  ]);

  console.log("ğŸ§© Prompt template created");

  // 5ï¸âƒ£ Buat chain runnable
  const chain = RunnableSequence.from([
    {
      history: async () => {
        const vars = await memory.loadMemoryVariables({});
        console.log("ğŸ“š Loaded memory variables:", vars);
        return vars.history || [];
      },
      input: (input) => input.input,
    },
    prompt,
    llm,
    async (output, { input }) => {
      console.log("ğŸ¤– Model output received:", output);
      await memory.saveContext(
        { input: input || userMessage },
        { output: output.content }
      );
      console.log("âœ… Context saved to memory");
      return output.content;
    },
  ]);

  // 6ï¸âƒ£ Jalankan agent
  console.log("ğŸš€ Running agent chain...");
  const response = await chain.invoke({ input: userMessage || "(no message)" });

  console.log("ğŸ’¬ Final response:", response);
  return response;
}
